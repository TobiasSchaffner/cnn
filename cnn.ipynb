{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x4HI2mpwlrcn"
      },
      "source": [
        "# Deep Learning - Student Research Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J4dtfpg4xeP",
        "colab_type": "text"
      },
      "source": [
        "You can use the left link to run this jupiter notebook on google colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "klAltGp8ycek"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/TobiasSchaffner/cnn/blob/master/cnn.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/TobiasSchaffner/cnn/blob/master/cnn.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4vWzuPK5GrX",
        "colab_type": "text"
      },
      "source": [
        "We have to import the needed libraries. I used tenorflow keras and google colab. Numpy is used for math and matrices and matplotlib for visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iAve6DCL4JH4",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh_hSPJ69Ntc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "number_of_train_images: int = len(train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G6iyWig5wTb",
        "colab_type": "text"
      },
      "source": [
        "The CIFAR10 dataset is labeled with ten classes. We do a remapping to a binary label. If the picture is in one of the classes 2 to 7 we label it as living. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qvqCPD1ZhBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_living(label: int) -> int:\n",
        "  \"\"\"\n",
        "  Map a CIFAR10 class label to one for living and zero for not living.\n",
        "\n",
        "  :param label: A CIFAR10 class label in range between zero and nine.\n",
        "  :type label:  int\n",
        "\n",
        "  :result:      One for living and zero for not living.\n",
        "  :type result: int\n",
        "  \"\"\"\n",
        "  return int(label in (2, 3, 4, 5, 6, 7))\n",
        "\n",
        "def map_to_is_living(labels: numpy.ndarray) -> numpy.ndarray:\n",
        "  for i in range(len(labels)):\n",
        "    labels[i][0] = is_living(labels[i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2OeIUSX6Vmc",
        "colab_type": "text"
      },
      "source": [
        "We load the CIFAR10 dataset using keras. The dataset is not yet labled as needed but we can use our new mapping function to relabel it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JWoEqyMuXFF4",
        "colab": {}
      },
      "source": [
        "# Map the labels to values 1 for is living and 0 for is not living\n",
        "map_to_is_living(train_labels)\n",
        "map_to_is_living(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OAcW1DV9JfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate_images(images: numpy.ndarray, angle: float) -> numpy.ndarray:\n",
        "  result = images.copy()\n",
        "  for i in range(len(images)):\n",
        "    result[i] = imutils.rotate(images[i], angle)\n",
        "  return result\n",
        "\n",
        "def translate_images(images: numpy.ndarray, x_trans: int, y_trans: int) -> numpy.ndarray:\n",
        "  result = images.copy()\n",
        "  for i in range(len(images)):\n",
        "    result[i] = imutils.translate(images[i], x_trans, y_trans)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXQVPExKA7zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = numpy.concatenate((train_images,\n",
        "                                  rotate_images(train_images, 10),\n",
        "                                  rotate_images(train_images, -10),\n",
        "                                  translate_images(train_images, -5, 0),\n",
        "                                  translate_images(train_images, 5, 0),\n",
        "                                  translate_images(train_images, 0, -5),\n",
        "                                  translate_images(train_images, 0, 5)))\n",
        "\n",
        "train_labels = numpy.concatenate((train_labels,\n",
        "                                  train_labels,\n",
        "                                  train_labels,\n",
        "                                  train_labels,\n",
        "                                  train_labels,\n",
        "                                  train_labels,\n",
        "                                  train_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAEcPbZC9FwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQvowfoe7C8w",
        "colab_type": "text"
      },
      "source": [
        "Let's create a preview of the classes using matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6bB0Ij8R7B3C",
        "colab": {}
      },
      "source": [
        "class_names = ['not living', 'living']\n",
        "regularizations = ['normal', 'rotated_right', 'rotated_left', 'translated_left', 'translated_right', 'translated_up', 'translated_down']\n",
        "\n",
        "figure = plt.figure(figsize=(20,10))\n",
        "\n",
        "for regularization in range(len(regularizations)):\n",
        "  for i in range(10):\n",
        "      plt.subplot(7,10,regularization * 10 + i+1)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.grid(False)\n",
        "      plt.imshow(train_images[regularization * number_of_train_images + i],\n",
        "                 cmap=plt.cm.binary)\n",
        "      if (regularization == len(regularizations) - 1):\n",
        "        plt.xlabel(class_names[train_labels[i][0]])\n",
        "      if (i == 0):\n",
        "        plt.ylabel(regularizations[regularization])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3hQvqXpNyN3x"
      },
      "source": [
        "The 6 lines of code below define the convolutional base using a common pattern: a stack of [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers.\n",
        "\n",
        "As input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size. If you are new to these dimensions, color_channels refers to (R,G,B). In this example, you will configure our CNN to process inputs of shape (32, 32, 3), which is the format of CIFAR images. You can do this by passing the argument `input_shape` to our first layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L9YmGQBQPrdn",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dropout(0.2, input_shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ipGiQMcR4Gtq"
      },
      "source": [
        "Let's get a summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Yu_m-TZUWGX",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xNKXi-Gy3RO-"
      },
      "source": [
        "As you can see, our (3, 3, 64) outputs were flattened into vectors of shape (576) before going through two Dense layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MdDzI75PUXrG",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=20, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gtyDF0MKUcM7",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0LvwaKhtUdOo",
        "colab": {}
      },
      "source": [
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}